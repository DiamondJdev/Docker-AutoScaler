worker_processes auto;
error_log /var/log/nginx/error.log warn;
pid /var/run/nginx.pid;

events {
    worker_connections 2048;
    use epoll;
    multi_accept on;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    # Logging format with load balancing info
    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for" '
                    'rt=$request_time uct="$upstream_connect_time" '
                    'uht="$upstream_header_time" urt="$upstream_response_time" '
                    'upstream_addr="$upstream_addr"';

    access_log /var/log/nginx/access.log main;

    # Basic settings optimized for high load
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;
    client_max_body_size 20M;

    # Buffer settings for high concurrency
    client_body_buffer_size 128k;
    client_header_buffer_size 1k;
    large_client_header_buffers 4 4k;
    output_buffers 1 32k;
    postpone_output 1460;

    # Gzip compression
    gzip on;
    gzip_vary on;
    gzip_min_length 1024;
    gzip_proxied any;
    gzip_comp_level 6;
    gzip_types
        text/plain
        text/css
        text/xml
        text/javascript
        application/json
        application/javascript
        application/xml+rss
        application/atom+xml
        image/svg+xml;

    # Rate limiting with higher capacity for auto-scaling
    limit_req_zone $binary_remote_addr zone=api:200m rate=20000r/m;
    limit_req_zone $binary_remote_addr zone=login:100m rate=2000r/m;

    # Connection limiting
    limit_conn_zone $binary_remote_addr zone=conn_limit_per_ip:10m;
    limit_conn_zone $server_name zone=conn_limit_per_server:10m;

    # Upstream backend servers with service discovery
    # Docker Swarm automatically resolves 'api' to all healthy instances
    upstream api_backend {
        # Use Docker Swarm's built-in load balancing
        # The 'api' service name resolves to all healthy replicas
        server api:3000 max_fails=3 fail_timeout=30s;
        
        # Keepalive connections to reduce latency
        keepalive 32;
        keepalive_requests 100;
        keepalive_timeout 60s;
    }

    # Health check upstream for monitoring
    upstream health_check {
        server api:3000;
        keepalive 8;
    }

    server {
        listen 80;
        server_name localhost;

        # Connection limits
        limit_conn conn_limit_per_ip 50;
        limit_conn conn_limit_per_server 1000;

        # Security headers
        add_header X-Frame-Options "SAMEORIGIN" always;
        add_header X-XSS-Protection "1; mode=block" always;
        add_header X-Content-Type-Options "nosniff" always;
        add_header Referrer-Policy "no-referrer-when-downgrade" always;
        add_header Content-Security-Policy "default-src 'self' http: https: data: blob: 'unsafe-inline'" always;
        add_header X-Load-Balancer "nginx-swarm" always;

        # API routes with enhanced load balancing
        location /api/ {
            # Rate limiting for auto-scaling environment
            limit_req zone=api burst=10000 nodelay;
            
            # Proxy settings optimized for Docker Swarm
            proxy_pass http://api_backend;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection "";
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_cache_bypass $http_upgrade;
            
            # Timeouts optimized for scaling
            proxy_connect_timeout 10s;
            proxy_send_timeout 30s;
            proxy_read_timeout 30s;
            
            # Retry logic for failed requests
            proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504;
            proxy_next_upstream_tries 3;
            proxy_next_upstream_timeout 10s;
        }

        # Special handling for login with separate rate limiting
        location /api/users/login {
            limit_req zone=login burst=1000 nodelay;
            
            proxy_pass http://api_backend;
            proxy_http_version 1.1;
            proxy_set_header Connection "";
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504;
            proxy_next_upstream_tries 2;
        }

        # Health check endpoint (no rate limiting, for monitoring)
        location /api/health {
            proxy_pass http://health_check;
            proxy_http_version 1.1;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            # Short cache for health checks
            proxy_cache_valid 200 5s;
            
            # Quick failover for health checks
            proxy_connect_timeout 2s;
            proxy_read_timeout 5s;
        }

        # Load balancer status endpoint
        location /nginx/status {
            access_log off;
            return 200 '{"status":"healthy","upstream_servers":"$upstream_addr","timestamp":"$time_iso8601"}';
            add_header Content-Type application/json;
        }

        # Upstream status for monitoring
        location /nginx/upstream {
            access_log off;
            return 200 '{"upstream":"api_backend","algorithm":"round_robin","health_checks":true}';
            add_header Content-Type application/json;
        }

        # Static content caching
        location ~* \.(jpg|jpeg|png|gif|ico|css|js)$ {
            expires 1y;
            add_header Cache-Control "public, immutable";
        }

        # Default route - API information
        location / {
            return 200 '{"message":"Auto-Scaling Backend API","version":"2.0.0","load_balancer":"nginx-swarm","endpoints":["/api/health","/api/users","/api/tasks"],"scaling":"enabled"}';
            add_header Content-Type application/json;
        }

        # Error pages
        error_page 502 503 504 @maintenance;
        location @maintenance {
            return 503 '{"error":"Service temporarily unavailable","message":"System is scaling, please retry in a few seconds"}';
            add_header Content-Type application/json;
        }
    }
} 